//--------------------------------------------1-------------------------------------------------------

function lab2_task1() {
	let A = [0.042331714, 0.009100501, 0.024268003, 0.007781588, 0.014903719, 0.053020311, 0.003561066, 
	0.011210762, 0.056449486, 0.007781588, 0.01398048, 0.01595885, 0.021102611, 0.057372725, 0.062120812, 
	0.016486415, 0.0349512, 0.035083092, 0.036797679, 0.016354524, 0.005539436, 0.007517805, 0.007649697,
	0.004616196, 0.003429174, 0.00395674, 0.001318913, 0.017145872, 0.008045371, 0.000395674, 0.004879979, 0.010683197];
	/*	оруглённое до тысячных
	let p = [0.042, 0.009, 0.024, 0.008, 0.015, 0.053, 0.004, 0.011, 0.056, 0.008, 0.014, 0.016, 0.021, 0.057, 0.062, 0.017, 0.035, 0.035, 0.037, 0.016, 0.006, 0.008, 0.008,0.005, 0.003, 0.004, 0.001, 0.017, 0.008, 0.0004, 0.005, 0.011];*/	
	
	let H = entropy_alph(A);
	console.log( "Энтропия алфавита = " + H)
	return H;	
}

function entropy_alph(a) {
	let H = 0;
	
	for(let i = 0; i < a.length; i++) {
		H += -(a[i] * Math.log2(a[i]));
	}
	
	return H;
}


//--------------------------------------------2-------------------------------------------------------

function lab2_task2() {
	//Зорко одно лишь сердце. Самого главного глазами не увидишь.
	let str = "11010000 10010111 11010000 10111110 11010001 10000000 11010000 10111010 11010000 10111110 00100000 11010000 10111110 11010000 10110100 11010000 10111101 11010000 10111110 00100000 11010000 10111011 11010000 10111000 11010001 10001000 11010001 10001100 00100000 11010001 10000001 11010000 10110101 11010001 10000000 11010000 10110100 11010001 10000110 11010000 10110101 00101110 00100000 11010000 10100001 11010000 10110000 11010000 10111100 11010000 10111110 11010000 10110011 11010000 10111110 00100000 11010000 10110011 11010000 10111011 11010000 10110000 11010000 10110010 11010000 10111101 11010000 10111110 11010000 10110011 11010000 10111110 00100000 11010000 10110011 11010000 10111011 11010000 10110000 11010000 10110111 11010000 10110000 11010000 10111100 11010000 10111000 00100000 11010000 10111101 11010000 10110101 00100000 11010001 10000011 11010000 10110010 11010000 10111000 11010000 10110100 11010000 10111000 11010001 10001000 11010001 10001100 00101110";
	
	let zero = (str.match(/0/g) || []).length;
	let one = (str.match(/1/g) || []).length;
	let p = [];
	
	p.push(zero / str.length);
	p.push(one / str.length);
	
	let h = entropy_bin(p);
	console.log("Энтропия бинарной строки = "+ h) ;
	return h;
}

function entropy_bin(p) {
	let H = 0;

	H = -p[0] * Math.log2(p[0]) - p[1] * Math.log2(p[1]);  //2.4

	return H;
}


//--------------------------------------------3-------------------------------------------------------

function lab2_task3() {
	let str = "Войцехович Екатерина Алексеевна";
	let bin_str = "";

	for(let i = 0; i < str.length; i++) {
		bin = str.charCodeAt(i); //числовое значение Юникода для символа по индексу 
		bin_str += decToBin(parseInt(bin));
	}

	let info_from_a = lab2_task1() * str.length;
	let inf_from_b = lab2_task2() * bin_str.length;
	console.log("Количество информации в сообщении");
	console.log("на основе исходного алфавита: " + info_from_a );
	console.log("в кодах ASCII: " + inf_from_b );
}

function decToBin(dec) {
	let binary= parseInt(dec.toString(), 2);
	return binary;
}


//--------------------------------------------4-------------------------------------------------------

function lab2_task4() {
	let str = "Войцехович Екатерина Алексеевна";
	let bin_str = "";

	for(let i = 0; i < str.length; i++) {
		bin = str.charCodeAt(i);
		bin_str += decToBin(parseInt(bin));
	}

	console.log("Для q=0.1");
	let inf = mistaken_entropy(0.1) * str.length;
	let inf_bin = mistaken_entropy(0.1) * bin_str.length;
	console.log("a) " + inf);
	console.log("б) " + inf_bin );

	console.log("Для q=0.5 ");
	inf = mistaken_entropy(0.5) * str.length;
	inf_bin = mistaken_entropy(0.5) * bin_str.length;
	console.log("a) " + inf );
	console.log("б) " + inf_bin );

	console.log("Для q=1 ");
	inf = mistaken_entropy(1) * str.length;
	inf_bin = mistaken_entropy(1) * bin_str.length;
	console.log("a) " + inf);
	console.log("б) " + inf_bin );
}


function mistaken_entropy(q) {
	let p = 1 - q;
	if(p != 0 && p != 0.5) {
		h_u = -p * Math.log2(p) - q * Math.log2(q);
		h = 1 - h_u;
	} else
	if(p == 0) {
		h = 0;
	} else {
		h = -Math.log2(p);
	}
	return h;
}
